![alt text](image.png)
# Inference HTML UI

This project provides a simple and intuitive user interface for interacting with the Ollama and Llama.cpp streaming endpoints. It is built using plain HTML and JavaScript, making it lightweight and easy to integrate into any web project.

The UI allows users to select between different inference URLs, start a chat, and view metrics such as the time to start chat and typing speed (in characters per second). This makes it a versatile tool for testing and interacting with AI models served by the Ollama and Llama.cpp servers.

## Setup

1. Open the `index.html` file in your web browser.

2. Select the desired inference URL from the dropdown menu.

3. Enter your question in the input field and submit the form.

4. The response from the server will be displayed on the page.


## Features

Supported Endpoints
* ollama
* llama.cpp

UI Features
* Text Streaming
* Stoppable
* Spinner
* Bootstrap CSS
* Vanilla HTML/JS

## Contact
skale.dev

## License

This project is licensed under the terms of the MIT license.