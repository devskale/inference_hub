{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient, HfApi\n",
    "from credgoo import get_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached API key for huggingface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannwaldherr/code/python-utils/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'list_deployed_models' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.33.0'. HF Inference API is getting revamped and will only support warm models in the future (no cold start allowed). Use `HfApi.list_models(..., inference_provider='...')` to list warm models per provider.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#hf_api = HfApi()\n",
    "#models = api.list_models()\n",
    "\n",
    "\n",
    "\n",
    "HUGGINGFACE_TOKEN = get_api_key(\"huggingface\")\n",
    "\n",
    "\n",
    "client = InferenceClient(token=HUGGINGFACE_TOKEN)\n",
    "models = client.list_deployed_models(frameworks=\"text-generation-inference\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image-text-to-text': ['HuggingFaceM4/idefics2-8b', 'Qwen/Qwen2-VL-2B-Instruct', 'Qwen/Qwen2-VL-7B-Instruct', 'Qwen/Qwen2.5-VL-7B-Instruct'], 'text-generation': ['bigcode/santacoder', 'bigcode/starcoder', 'bigcode/starcoder2-15b', 'bigcode/starcoder2-3b', 'bigcode/starcoderplus', 'bilalRahib/TinyLLama-NSFW-Chatbot', 'Bllossom/llama-3.2-Korean-Bllossom-3B', 'codellama/CodeLlama-13b-hf', 'codellama/CodeLlama-34b-Instruct-hf', 'codellama/CodeLlama-7b-hf', 'CohereForAI/c4ai-command-r-08-2024', 'deepseek-ai/DeepSeek-Coder-V2-Instruct', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-125m', 'EleutherAI/gpt-neo-2.7B', 'EleutherAI/gpt-neox-20b', 'facebook/incoder-6B', 'facebook/opt-1.3b', 'facebook/opt-350m', 'google/gemma-1.1-2b-it', 'google/gemma-1.1-7b-it', 'google/gemma-2-2b-it', 'google/gemma-2b', 'google/gemma-7b', 'HuggingFaceH4/starchat2-15b-v0.1', 'HuggingFaceH4/zephyr-7b-alpha', 'HuggingFaceH4/zephyr-7b-beta', 'HuggingFaceTB/SmolLM2-135M-Instruct', 'jinaai/reader-lm-1.5b', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-3.1-70B-Instruct', 'meta-llama/Llama-3.1-8B-Instruct', 'meta-llama/Llama-3.2-3B-Instruct', 'meta-llama/Llama-Guard-3-1B', 'meta-llama/Llama-Guard-3-8B', 'meta-llama/Meta-Llama-3-8B-Instruct', 'microsoft/DialoGPT-medium', 'microsoft/Phi-3-mini-4k-instruct', 'microsoft/Phi-3.5-mini-instruct', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-Instruct-v0.3', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-Nemo-Instruct-2407', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'openai-community/gpt2', 'OpenAssistant/oasst-sft-1-pythia-12b', 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'Pi3141/DialoGPT-medium-elon-2', 'Qwen/Qwen1.5-0.5B-Chat', 'Qwen/Qwen2.5-1.5B-Instruct', 'Qwen/Qwen2.5-3B', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/Qwen2.5-Math-1.5B-Instruct', 'rinna/japanese-gpt2-medium', 'Salesforce/codegen-350M-mono', 'tiiuae/falcon-7b-instruct', 'tiiuae/falcon-rw-1b', 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'uer/gpt2-chinese-cluecorpussmall', 'unsloth/Llama-3.2-3B-Instruct']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Pretty print the models dictionary with indentation\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HfApi.list_models() got an unexpected keyword argument 'inference_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Use root method\u001b[39;00m\n\u001b[32m      4\u001b[39m hf_api = HfApi(\n\u001b[32m      5\u001b[39m     token=HUGGINGFACE_TOKEN\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m models = \u001b[43mhf_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43minference_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/python-utils/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: HfApi.list_models() got an unexpected keyword argument 'inference_provider'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Use root method\n",
    "hf_api = HfApi(\n",
    "    token=HUGGINGFACE_TOKEN\n",
    "    )\n",
    "models = hf_api.list_models(\n",
    "    inference_provider=\"huggingface\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"image-text-to-text\": [\n",
      "        \"HuggingFaceM4/idefics2-8b\",\n",
      "        \"Qwen/Qwen2-VL-2B-Instruct\",\n",
      "        \"Qwen/Qwen2-VL-7B-Instruct\",\n",
      "        \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
      "    ],\n",
      "    \"text-generation\": [\n",
      "        \"bigcode/santacoder\",\n",
      "        \"bigcode/starcoder\",\n",
      "        \"bigcode/starcoder2-15b\",\n",
      "        \"bigcode/starcoder2-3b\",\n",
      "        \"bigcode/starcoderplus\",\n",
      "        \"bilalRahib/TinyLLama-NSFW-Chatbot\",\n",
      "        \"Bllossom/llama-3.2-Korean-Bllossom-3B\",\n",
      "        \"codellama/CodeLlama-13b-hf\",\n",
      "        \"codellama/CodeLlama-34b-Instruct-hf\",\n",
      "        \"codellama/CodeLlama-7b-hf\",\n",
      "        \"CohereForAI/c4ai-command-r-08-2024\",\n",
      "        \"deepseek-ai/DeepSeek-Coder-V2-Instruct\",\n",
      "        \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
      "        \"EleutherAI/gpt-neo-1.3B\",\n",
      "        \"EleutherAI/gpt-neo-125m\",\n",
      "        \"EleutherAI/gpt-neo-2.7B\",\n",
      "        \"EleutherAI/gpt-neox-20b\",\n",
      "        \"facebook/incoder-6B\",\n",
      "        \"facebook/opt-1.3b\",\n",
      "        \"facebook/opt-350m\",\n",
      "        \"google/gemma-1.1-2b-it\",\n",
      "        \"google/gemma-1.1-7b-it\",\n",
      "        \"google/gemma-2-2b-it\",\n",
      "        \"google/gemma-2b\",\n",
      "        \"google/gemma-7b\",\n",
      "        \"HuggingFaceH4/starchat2-15b-v0.1\",\n",
      "        \"HuggingFaceH4/zephyr-7b-alpha\",\n",
      "        \"HuggingFaceH4/zephyr-7b-beta\",\n",
      "        \"HuggingFaceTB/SmolLM2-135M-Instruct\",\n",
      "        \"jinaai/reader-lm-1.5b\",\n",
      "        \"meta-llama/Llama-2-13b-chat-hf\",\n",
      "        \"meta-llama/Llama-2-70b-chat-hf\",\n",
      "        \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "        \"meta-llama/Llama-3.1-70B-Instruct\",\n",
      "        \"meta-llama/Llama-3.1-8B-Instruct\",\n",
      "        \"meta-llama/Llama-3.2-3B-Instruct\",\n",
      "        \"meta-llama/Llama-Guard-3-1B\",\n",
      "        \"meta-llama/Llama-Guard-3-8B\",\n",
      "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "        \"microsoft/DialoGPT-medium\",\n",
      "        \"microsoft/Phi-3-mini-4k-instruct\",\n",
      "        \"microsoft/Phi-3.5-mini-instruct\",\n",
      "        \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
      "        \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
      "        \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
      "        \"mistralai/Mistral-7B-v0.1\",\n",
      "        \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
      "        \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
      "        \"openai-community/gpt2\",\n",
      "        \"OpenAssistant/oasst-sft-1-pythia-12b\",\n",
      "        \"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\",\n",
      "        \"Pi3141/DialoGPT-medium-elon-2\",\n",
      "        \"Qwen/Qwen1.5-0.5B-Chat\",\n",
      "        \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
      "        \"Qwen/Qwen2.5-3B\",\n",
      "        \"Qwen/Qwen2.5-72B-Instruct\",\n",
      "        \"Qwen/Qwen2.5-Math-1.5B-Instruct\",\n",
      "        \"rinna/japanese-gpt2-medium\",\n",
      "        \"Salesforce/codegen-350M-mono\",\n",
      "        \"tiiuae/falcon-7b-instruct\",\n",
      "        \"tiiuae/falcon-rw-1b\",\n",
      "        \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
      "        \"uer/gpt2-chinese-cluecorpussmall\",\n",
      "        \"unsloth/Llama-3.2-3B-Instruct\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#print(list(models))\n",
    "print(json.dumps(models, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id, likes, downloads\n",
      "meta-llama/Llama-4-Scout-17B-16E-Instruct 752 540831 image-text-to-text\n",
      "HiDream-ai/HiDream-I1-Full 321 6542 text-to-image\n",
      "deepseek-ai/DeepSeek-V3-0324 2553 207852 text-generation\n",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct 287 27990 image-text-to-text\n",
      "black-forest-labs/FLUX.1-dev 9787 2094597 text-to-image\n",
      "deepseek-ai/DeepSeek-R1 11885 1426681 text-generation\n",
      "HiDream-ai/HiDream-I1-Dev 69 3084 text-to-image\n",
      "google/gemma-3-27b-it 1163 999332 image-text-to-text\n",
      "openfree/flux-chatgpt-ghibli-lora 232 12230 text-to-image\n",
      "HiDream-ai/HiDream-I1-Fast 43 3769 text-to-image\n",
      "stabilityai/stable-diffusion-3.5-large 2658 136289 text-to-image\n",
      "Qwen/QwQ-32B 2666 793470 text-generation\n",
      "sentence-transformers/all-MiniLM-L6-v2 3250 87595792 sentence-similarity\n",
      "openai/whisper-large-v3-turbo 2263 3042400 automatic-speech-recognition\n",
      "Qwen/Qwen2.5-VL-7B-Instruct 818 2130878 image-text-to-text\n",
      "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8 93 24390 image-text-to-text\n",
      "black-forest-labs/FLUX.1-schnell 3643 1484756 text-to-image\n",
      "mistralai/Mistral-7B-Instruct-v0.3 1607 804544 text-generation\n",
      "openai/whisper-large-v3 4267 4871113 automatic-speech-recognition\n",
      "meta-llama/Llama-3.1-8B-Instruct 3831 5961887 text-generation\n",
      "stable-diffusion-v1-5/stable-diffusion-v1-5 497 5758618 text-to-image\n",
      "Wan-AI/Wan2.1-T2V-14B 1175 69752 text-to-video\n",
      "stabilityai/stable-diffusion-xl-base-1.0 6492 2484448 text-to-image\n",
      "meta-llama/Llama-3.3-70B-Instruct 2252 1083754 text-generation\n",
      "codermert/gamzekocc_fluxx 130 1992 text-to-image\n",
      "deepseek-ai/DeepSeek-V3 3804 682497 text-generation\n",
      "codermert/baharrr_fluxxx 77 499 text-to-image\n",
      "Qwen/Qwen2.5-7B-Instruct 633 2563499 text-generation\n",
      "meta-llama/Llama-3.2-3B-Instruct 1351 1346167 text-generation\n",
      "codermert/ezelll_flux 61 329 text-to-image\n",
      "codermert/busra_fluxx 31 115 text-to-image\n",
      "codermert/burcu2_fluxxx 56 283 text-to-image\n",
      "intfloat/multilingual-e5-large-instruct 419 990486 feature-extraction\n",
      "Lightricks/LTX-Video 1126 126597 text-to-video\n",
      "microsoft/phi-4 1983 545750 text-generation\n",
      "meta-llama/Meta-Llama-3-8B-Instruct 3913 1089683 text-generation\n",
      "Qwen/Qwen2.5-Coder-32B-Instruct 1780 468637 text-generation\n",
      "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B 1323 2416404 text-generation\n",
      "meta-llama/Llama-3.2-1B-Instruct 875 2284858 text-generation\n",
      "google-bert/bert-base-uncased 2216 79209803 fill-mask\n",
      "openai-community/gpt2 2664 13307708 text-generation\n",
      "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 853 9340546 sentence-similarity\n",
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0 1218 1014315 text-generation\n",
      "perplexity-ai/r1-1776 2223 12468 text-generation\n",
      "meta-llama/Llama-2-7b-chat-hf 4367 1249854 text-generation\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1 4377 520474 text-generation\n",
      "Qwen/Qwen2.5-32B-Instruct 257 382892 text-generation\n",
      "Qwen/Qwen2.5-1.5B-Instruct 401 877071 text-generation\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B 695 888519 text-generation\n",
      "stabilityai/stable-diffusion-xl-refiner-1.0 1871 1328887 image-to-image\n",
      "tencent/HunyuanVideo 1810 2465 text-to-video\n",
      "facebook/bart-large-mnli 1352 2959218 zero-shot-classification\n",
      "mistralai/Mistral-7B-Instruct-v0.1 1630 342050 text-generation\n",
      "Falconsai/nsfw_image_detection 568 87017012 image-classification\n",
      "microsoft/Phi-3-mini-4k-instruct 1169 922181 text-generation\n",
      "stabilityai/stable-diffusion-3-medium 4753 16030 text-to-image\n",
      "meta-llama/Llama-3.2-11B-Vision-Instruct 1412 1320132 image-text-to-text\n",
      "ali-vilab/In-Context-LoRA 589 124393 text-to-image\n",
      "openfree/claude-monet 67 10516 text-to-image\n",
      "facebook/nllb-200-distilled-600M 619 1054554 translation\n",
      "HuggingFaceH4/zephyr-7b-beta 1688 597756 text-generation\n",
      "facebook/seamless-m4t-v2-large 810 66080 automatic-speech-recognition\n",
      "THUDM/CogVideoX-5b 602 70451 text-to-video\n",
      "stabilityai/stable-diffusion-3.5-medium 669 344645 text-to-image\n",
      "openfree/string-sandal 13 293 text-to-image\n",
      "openai/clip-vit-base-patch32 660 15138780 zero-shot-image-classification\n",
      "sentence-transformers/all-mpnet-base-v2 1038 35858199 sentence-similarity\n",
      "mistralai/Mistral-7B-Instruct-v0.2 2711 2163053 text-generation\n",
      "google/gemma-2-2b-it 1049 371868 text-generation\n",
      "Qwen/Qwen2-Audio-7B-Instruct 411 72955 audio-text-to-text\n",
      "Qwen/Qwen2.5-Coder-7B-Instruct 459 307271 text-generation\n",
      "stabilityai/stable-diffusion-3.5-large-turbo 570 77315 text-to-image\n",
      "black-forest-labs/FLUX.1-Redux-dev 476 286251 None\n",
      "strangerzonehf/Flux-Midjourney-Mix2-LoRA 469 22914 text-to-image\n",
      "openfree/boris-yeltsin 12 148 text-to-image\n",
      "openfree/morgenstern 11 155 text-to-image\n",
      "Qwen/Qwen2.5-VL-72B-Instruct 427 325461 image-text-to-text\n",
      "openfree/voice-crown-necklace 13 842 text-to-image\n",
      "strangerzonehf/Ghibli-Flux-Cartoon-LoRA 14 690 text-to-image\n",
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english 733 6490702 text-classification\n",
      "sentence-transformers/paraphrase-multilingual-mpnet-base-v2 376 3195005 sentence-similarity\n",
      "google/flan-t5-large 740 1002901 text2text-generation\n",
      "intfloat/multilingual-e5-large 909 1937811 feature-extraction\n",
      "google/gemma-2b-it 724 115902 text-generation\n",
      "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct 420 462481 text-generation\n",
      "ginipick/flux-lora-eric-cat 84 392 text-to-image\n",
      "seawolf2357/flux-lora-car-rolls-royce 38 440 text-to-image\n",
      "seawolf2357/flux-lora-military-artillery-k9 17 150 text-to-image\n",
      "seawolf2357/hanbok 36 4927 text-to-image\n",
      "seawolf2357/ntower 32 103 text-to-image\n",
      "strangerzonehf/Flux-Ghibli-Art-LoRA 61 2792 text-to-image\n",
      "openfree/flux-lora-korea-palace 43 1754 text-to-image\n",
      "openfree/korea-president-yoon 16 160 text-to-image\n",
      "openfree/president-k-dj 13 331 text-to-image\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B 659 244589 text-generation\n",
      "openfree/president-pjh 13 133 text-to-image\n",
      "openfree/pepe 33 372 text-to-image\n",
      "Efficient-Large-Model/Sana_Sprint_1.6B_1024px_diffusers 11 0 text-to-image\n",
      "facebook/bart-large-cnn 1347 4320369 summarization\n",
      "openai/whisper-tiny 305 688703 automatic-speech-recognition\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "\n",
    "hf_api = HfApi(\n",
    "    token=HUGGINGFACE_TOKEN,\n",
    "    library_name=\"text-generation-inference\",\n",
    ")\n",
    "print(\"id, likes, downloads\")\n",
    "#for model in hf_api.list_models(inference=\"warm\", filter=[\"text-generation\", \"video-text-to-text\"], sort=\"likes7d\", limit=100):\n",
    "for model in hf_api.list_models(inference=\"warm\", sort=\"likes7d\", limit=100):\n",
    "    print(model.id, model.likes, model.downloads, model.pipeline_tag)#, model.tags\n",
    "#for model in hf_api.list_models(filter=\"text-generation\", sort=\"likes7d\", limit=45):\n",
    "#    print(model.id, model.likes, model.downloads, model.library_name, model.pipeline_tag)#, model.tags)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
